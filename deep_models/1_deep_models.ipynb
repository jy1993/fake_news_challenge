{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torchnet as tnt\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from deep_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_iter, loss_fun, opt):\n",
    "    model.train()\n",
    "    meter = tnt.meter.AverageValueMeter()\n",
    "    meter.reset()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for headlines, bodies, labels in tqdm(data_iter):\n",
    "        opt.zero_grad()\n",
    "        headlines = torch.from_numpy(headlines).cuda().long()\n",
    "        bodies = torch.from_numpy(bodies).cuda().long()\n",
    "        y_true.extend(labels)\n",
    "        labels = torch.from_numpy(labels).cuda().long()\n",
    "        out, _, _ = model(headlines, bodies)\n",
    "        _, index = torch.max(out, dim=1)\n",
    "        y_pred.extend(index.cpu().data.numpy())\n",
    "        loss = loss_fun(out, labels)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        meter.add(loss.item())\n",
    "    return meter.value()[0]\n",
    "\n",
    "def val_model(model, data_iter, loss_fun):\n",
    "    model.eval()\n",
    "    meter = tnt.meter.AverageValueMeter()\n",
    "    meter.reset()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for headlines, bodies, labels in tqdm(data_iter):\n",
    "            headlines = torch.from_numpy(headlines).cuda().long()\n",
    "            bodies = torch.from_numpy(bodies).cuda().long()\n",
    "            y_true.extend(labels)\n",
    "            labels = torch.from_numpy(labels).cuda().long()\n",
    "            out, _, _ = model(headlines, bodies)\n",
    "            _, index = torch.max(out, dim=1)\n",
    "            y_pred.extend(index.cpu().data.numpy())\n",
    "            loss = loss_fun(out, labels)\n",
    "            meter.add(loss.item())\n",
    "\n",
    "    model.train()\n",
    "    return meter.value()[0]\n",
    "\n",
    "def test_model(model, data_iter):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for headlines, bodies, labels in tqdm(data_iter):\n",
    "            headlines = torch.from_numpy(headlines).cuda().long()\n",
    "            bodies = torch.from_numpy(bodies).cuda().long()\n",
    "            y_true.extend(labels)\n",
    "            labels = torch.from_numpy(labels).cuda().long()\n",
    "            out, _, _ = model(headlines, bodies)\n",
    "            _, index = torch.max(out, dim=1)\n",
    "            y_pred.extend(index.cpu().data.numpy())\n",
    "\n",
    "    model.train()\n",
    "    print('classification report:')\n",
    "    print('accuracy: %.3f' % accuracy_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('macro f1: %.3f' % f1_score(y_true, y_pred, average='macro'))\n",
    "    print('score: %.3f' % (get_score(y_true, y_pred) / get_score(y_true, y_true)))\n",
    "    \n",
    "def get_proba(model, data_iter):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for headlines, bodies, labels in tqdm(data_iter):\n",
    "            headlines = torch.from_numpy(headlines).cuda().long()\n",
    "            bodies = torch.from_numpy(bodies).cuda().long()\n",
    "            y_true.extend(labels)\n",
    "            labels = torch.from_numpy(labels).cuda().long()\n",
    "            out, _, _ = model(headlines, bodies)\n",
    "            y_pred.extend(out.cpu().data.numpy())\n",
    "\n",
    "    model.train()\n",
    "    return y_pred\n",
    "    \n",
    "    \n",
    "def test_get_batch(data_iter):\n",
    "    for headlines, bodies, labels in tqdm(data_iter):\n",
    "        #print(headlines.shape)\n",
    "        print(bodies.shape)\n",
    "        #print(labels.shape)\n",
    "    \n",
    "def my_plot(data):\n",
    "    plt.plot(data['train'])\n",
    "    plt.plot(data['val'])\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.show()\n",
    "    print('best epoch num: %s loss: %.3f' % (np.argmin(data['val']) +1, min(data['val'])))\n",
    "\n",
    "#test_get_batch(get_batch('./tmp/val_ids.pkl', batch_size=64, max_len_b=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_file_name = './tmp/pretrained.pkl'\n",
    "train_filename = './tmp/train_ids.pkl'\n",
    "val_filename = './tmp/val_ids.pkl'\n",
    "test_filename = './tmp/test_ids.pkl'\n",
    "vecs = pickle.load(open(pretrained_file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DIIN(nn.Module):\n",
    "    \"\"\"docstring for DIIN\"\"\"\n",
    "    def __init__(self, pretrained, model_name, hid_size=100, dropout=0.5):\n",
    "        super(DIIN, self).__init__()\n",
    "        vocab_size, emb_size = pretrained.shape\n",
    "        self.hid_size = hid_size\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(pretrained).float())\n",
    "        self.gru_enc = nn.LSTM(input_size=emb_size, hidden_size=hid_size, \n",
    "            batch_first=True, bidirectional=False)\n",
    "        \n",
    "        if model_name == 'diin_my':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(hid_size, 64, 1), \n",
    "\n",
    "                nn.Conv2d(64, 128, 7, 1, 3, bias=False), \n",
    "                nn.BatchNorm2d(128), \n",
    "                nn.ReLU(), \n",
    "                nn.AdaptiveMaxPool2d((32, 32)),\n",
    "\n",
    "                nn.Conv2d(128, 128, 3, 1, 1, bias=False), \n",
    "                nn.BatchNorm2d(128), \n",
    "                nn.ReLU(), \n",
    "                nn.AdaptiveMaxPool2d((16, 16)), \n",
    "                \n",
    "                nn.Conv2d(128, 256, 3, 1, 1, bias=False), \n",
    "                nn.BatchNorm2d(256), \n",
    "                nn.ReLU(), \n",
    "                nn.AdaptiveMaxPool2d((8, 8)), \n",
    "\n",
    "                nn.Conv2d(256, 256, 3, 1, 1, bias=False), \n",
    "                nn.BatchNorm2d(256), \n",
    "                nn.ReLU(), \n",
    "                nn.AdaptiveMaxPool2d((4, 4)),\n",
    "\n",
    "                nn.Conv2d(256, 512, 3, 1, 1, bias=False), \n",
    "                nn.BatchNorm2d(512), \n",
    "                nn.ReLU(), \n",
    "                nn.MaxPool2d(4),\n",
    "                ) \n",
    "\n",
    "            self.fc1 = nn.Linear(512, 100)\n",
    "\n",
    "        elif model_name == 'diin_densenet':\n",
    "            #self.features = DNet(args)\n",
    "            self.features = DNet(hid_size, block_config=(4, 4, 4), drop_rate=0.5, num_init_features=200)\n",
    "            \n",
    "            #self.features = DNet(args, block_config=(2, 2, 2), drop_rate=0.3, num_init_features=100)\n",
    "            #self.fc1 = nn.Linear(2016, 100)\n",
    "            self.fc1 = nn.Linear(2466, 100)\n",
    "            #self.fc1 = nn.Linear(3425, 100)\n",
    "        \n",
    "        elif model_name == 'diin_inception':\n",
    "            # input: 16 * 16\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(hid_size, 64, 1),\n",
    "\n",
    "                InceptionA(64, 32), \n",
    "                nn.MaxPool2d(2),\n",
    "\n",
    "                InceptionA(256, 32), \n",
    "                nn.MaxPool2d(2),\n",
    "\n",
    "                nn.Conv2d(256, 512, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(512), \n",
    "                nn.ReLU(), \n",
    "                nn.AvgPool2d(4))\n",
    "\n",
    "            self.fc1 = nn.Linear(512, 100)\n",
    "        elif model_name == 'diin_inceptionB':\n",
    "            # input: 24 * 24\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(hid_size, 100, 1),\n",
    "                nn.BatchNorm2d(100),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                InceptionA(100, 32), \n",
    "                nn.MaxPool2d(2),\n",
    "\n",
    "                InceptionA(256, 64), \n",
    "                nn.MaxPool2d(2),\n",
    "                \n",
    "                InceptionA(288, 32),\n",
    "                nn.MaxPool2d(2), \n",
    "\n",
    "                nn.Conv2d(288, 512, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(512), \n",
    "                nn.ReLU(), \n",
    "                nn.AvgPool2d(3))\n",
    "\n",
    "            self.fc1 = nn.Linear(512, 100)\n",
    "        self.last_layer = nn.Linear(100, 4)\n",
    "        self.dp = nn.Dropout(self.dropout)\n",
    "        self.hn = HighWay(hid_size)\n",
    "            \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.embedding(x1)\n",
    "        x2 = self.embedding(x2)\n",
    "        \n",
    "        x1 = self.dp(self.hn(x1))\n",
    "        x2 = self.dp(self.hn(x2))\n",
    "\n",
    "        x1, _ = self.gru_enc(x1)\n",
    "        x2, _ = self.gru_enc(x2)\n",
    "        \n",
    "        x1 = x1.unsqueeze(2) # B * T * 1 * H\n",
    "        x2 = x2.unsqueeze(1) # B * 1 * T * H\n",
    "        x = x1 * x2 # B * T * T * H\n",
    "        #x_sub = x1 - x2\n",
    "        #x = torch.cat((x, x_sub), dim=3)\n",
    "        x = x.permute(0, 3, 1, 2) # B * H * T * T\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.features(x)\n",
    "        #print(x.size())\n",
    "        x = x.squeeze()\n",
    "        x = F.relu(self.dp(self.fc1(x)))\n",
    "        x = F.sigmoid(self.last_layer(x))\n",
    "        return x, x, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIIN(\n",
      "  (embedding): Embedding(399670, 100)\n",
      "  (gru_enc): LSTM(100, 100, batch_first=True)\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(100, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): AdaptiveMaxPool2d(output_size=(32, 32))\n",
      "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): AdaptiveMaxPool2d(output_size=(16, 16))\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): AdaptiveMaxPool2d(output_size=(8, 8))\n",
      "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): ReLU()\n",
      "    (16): AdaptiveMaxPool2d(output_size=(4, 4))\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=100, bias=True)\n",
      "  (last_layer): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (dp): Dropout(p=0.5)\n",
      "  (hn): HighWay()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09ad33198afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[1;31m#print(f\"epoch: {epoch + 1}/{epochs}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_aug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9bb99e2a177e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_iter, loss_fun, opt)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmeter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(42)\n",
    "model_name = 'DIIN'\n",
    "if model_name == 'EmbeddingBag':\n",
    "    model = EmbeddingBag(vecs).cuda()\n",
    "elif model_name == 'Esim':\n",
    "    model = Esim(vecs).cuda()\n",
    "elif model_name == 'DIIN':\n",
    "    model = DIIN(vecs, 'diin_my').cuda()\n",
    "    \n",
    "print(model)\n",
    "opt = Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)\n",
    "#weight = torch.Tensor([3, 3, 3, 1])\n",
    "#loss_fun = nn.CrossEntropyLoss(weight)\n",
    "#scheduler = ReduceLROnPlateau(opt, 'min', factor=0.1, patience=0, verbose=True)\n",
    "scheduler = StepLR(opt, step_size=4, gamma=0.1)\n",
    "loss_fun = FocalLoss(gamma=5)\n",
    "loss_fun.cuda()\n",
    "epochs = 6\n",
    "history = {'train':[], 'val': []}\n",
    "min_loss = 100.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #print(f\"epoch: {epoch + 1}/{epochs}\")\n",
    "    scheduler.step()\n",
    "    train_loss = train_model(model, get_batch(train_filename, batch_size=32, max_len_b=100, data_aug=False), loss_fun, opt)\n",
    "    val_loss = val_model(model, get_batch(val_filename, batch_size=32, max_len_b=100), loss_fun)\n",
    "    if val_loss < min_loss:\n",
    "        torch.save(model.state_dict(), './models/%s_%s_%.3f' % (model_name, epoch + 1, val_loss))\n",
    "        \n",
    "    #scheduler.step(val_loss)\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "    \n",
    "my_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [0.15486759472930867], 'val': [0.15710474238839256]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yanji\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\yanji\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification report:\n",
      "accuracy: 0.717\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       762\n",
      "          1       0.00      0.00      0.00       162\n",
      "          2       0.00      0.00      0.00      1800\n",
      "          3       0.72      1.00      0.84      6898\n",
      "\n",
      "avg / total       0.51      0.72      0.60      9622\n",
      "\n",
      "macro f1: 0.209\n",
      "score: 0.388\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c1abb1f0652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9bb99e2a177e>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, data_iter)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbodies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4aed38affd5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[1;31m#         print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[1;31m#print(x.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     )\n\u001b[1;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model_name = 'Esim'\n",
    "# if model_name == 'EmbeddingBag':\n",
    "#     model = EmbeddingBag(vecs).cuda()\n",
    "# elif model_name == 'CE':\n",
    "#     model = CE(vecs).cuda()\n",
    "# elif model_name == 'IE':\n",
    "#     model = IE(vecs).cuda()\n",
    "# elif model_name == 'Esim':\n",
    "#     model = Esim(vecs).cuda()\n",
    "# elif model_name == 'Dattn':\n",
    "#     model = Dattn(vecs).cuda()\n",
    "# elif model_name == 'Declare':\n",
    "#     model = Declare(vecs).cuda()\n",
    "\n",
    "# model.load_state_dict(torch.load('./models/Esim_10_0.069'))\n",
    "test_model(model, get_batch(val_filename, batch_size=64, max_len_b=100))\n",
    "print('*' * 50)\n",
    "test_model(model, get_batch(test_filename, batch_size=64, max_len_b=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "09cee0d188214dd9a409b73d292620ca": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "4dd3c3ad94da4869b5f5f734627157dd": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "722e14ad5f3d4cacae33f9986cfcbd60": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "8a4aa9cb8c1b495f8370a7274e5e87c5": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "e35465fac59b43b7895b6b9064df5b48": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
